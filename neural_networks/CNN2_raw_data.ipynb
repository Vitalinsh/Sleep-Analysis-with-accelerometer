{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZtLCrbxiIgJg"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iKCqU207IJrF"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#from google.colab import file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JRGXpB-8IJrQ"
   },
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"ICHI14_dataset\\data\")\n",
    "patient_list = ['002','003','005','007','08a','08b','09a','09b', '10a','011','013','014','15a','15b','016',\n",
    "            '017','018','019','020','021','022','023','025','026','027','028','029','030','031','032',\n",
    "            '033','034','035','036','037','038','040','042','043','044','045','047','048','049','051']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rAkhERdxIJrT"
   },
   "outputs": [],
   "source": [
    "train_patient_list, test_patient_list = train_test_split(patient_list, random_state=100, test_size=0.3)\n",
    "test_patient_list, valid_patient_list = train_test_split(test_patient_list, random_state=100, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YHxtdjtQlXiO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "31\n",
      "7\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(len(patient_list))\n",
    "print(len(train_patient_list))\n",
    "print(len(valid_patient_list))\n",
    "print(len(test_patient_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oVyQga2AmI7R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['022', '09b', '048', '020', '023', '15b', '003', '042', '15a', '038', '025', '011', '018', '029', '031', '014', '08a', '047', '049', '016', '040', '005', '037', '033', '013', '017', '026', '044', '007', '027', '10a']\n",
      "['035', '034', '051', '019', '045', '043', '08b']\n",
      "['021', '09a', '002', '028', '032', '036', '030']\n"
     ]
    }
   ],
   "source": [
    "print(train_patient_list)\n",
    "print(valid_patient_list)\n",
    "print(test_patient_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wj-8RYiRL2We"
   },
   "outputs": [],
   "source": [
    "def change_labels(sample):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    sample - contains only label 1(awake) and 0(sleep) for polisomnography\n",
    "    \"\"\"\n",
    "    \n",
    "    sample.gt[sample.gt==0] = 8\n",
    "    sample.gt[np.logical_or.reduce((sample.gt==1, sample.gt==2, sample.gt==3, sample.gt==5))] = 0\n",
    "    sample.gt[np.logical_or.reduce((sample.gt==6, sample.gt==7, sample.gt==8))] = 1\n",
    "    \n",
    "    return sample   \n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "def decoder(sample):\n",
    "    '''\n",
    "    Returns: \n",
    "    decoded_sample - contains accelerometer and ps data for each sensor record, ndarray of shape (n_records, 4)\n",
    "    \n",
    "    '''\n",
    "\n",
    "    sample = np.repeat(sample, sample.d, axis=0)\n",
    "    n_records = sample.shape[0]\n",
    "    decoded_sample = np.zeros((n_records, 4))\n",
    "    \n",
    "    decoded_sample[:, 0] = sample.x\n",
    "    decoded_sample[:, 1] = sample.y\n",
    "    decoded_sample[:, 2] = sample.z\n",
    "    decoded_sample[:, 3] = sample.gt\n",
    "    \n",
    "    return decoded_sample\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "def divide_by_windows(decoded_sample, window_len=60):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    wondow_len - length of each window in seconds, int\n",
    "    Returns:\n",
    "    X - accelerometer data, ndarray of shape (n_windows, window_len, 3)\n",
    "    y - polisomnography data, ndarray of shape (n_windows, )\n",
    "    \"\"\"\n",
    "    \n",
    "    window_len *= 100\n",
    "    n_windows = decoded_sample.shape[0] // window_len\n",
    "    \n",
    "    X = np.zeros((n_windows, window_len, 3))\n",
    "    y = np.zeros(n_windows)\n",
    "    \n",
    "    for i in range(n_windows):\n",
    "        X[i] = decoded_sample[window_len * i: window_len * i + window_len, 0: 3]\n",
    "        \n",
    "        ones = np.count_nonzero(decoded_sample[window_len*i: window_len*i+window_len, 3])\n",
    "        if ones >= (window_len / 2):\n",
    "            y[i] = 1\n",
    "        else:\n",
    "            y[i] = 0\n",
    "                \n",
    "    return X, y\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "def get_one_patient_data(data_path, patient, window_len=60):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    X, y - for one patient\n",
    "    \"\"\"\n",
    "    \n",
    "    sample = np.load(\"%s/p%s.npy\"%(data_path, patient)).view(np.recarray)\n",
    "    sample = change_labels(sample)\n",
    "    sample = decoder(sample)\n",
    "    X, y = divide_by_windows(sample, window_len)\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "def get_data_for_model(data_path, patient_list, window_len=60):\n",
    "    \n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    X, y - for all patient list, ndarray of shape (n_records, n_features, n_channels=3)\n",
    "    \"\"\"\n",
    "    \n",
    "    X_all_data = []\n",
    "    y_all_data = []\n",
    "    for patient in patient_list:\n",
    "        X, y = get_one_patient_data(data_path, patient, window_len)\n",
    "        X_all_data.append(X)\n",
    "        y_all_data.append(y)\n",
    "        \n",
    "    X_all_data = np.concatenate(X_all_data, axis=0)\n",
    "    y_all_data = np.concatenate(y_all_data, axis=0)\n",
    "    \n",
    "    return X_all_data, y_all_data\n",
    "  \n",
    "#-------------------------------------------------------------------------\n",
    "\n",
    "def get_dawnsampled_data(data_path, patient_list, window_len=60, dawnsample=\"pca\", n_components=10, n_windows=10):\n",
    "    \n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    dawnsample - \"pca\", \"mean\", \"max\", \"mode\", None - determine the type of data reducing\n",
    "    Returns:\n",
    "    X, y - reduced data for all patient list and combine several windows data, ndarray of shape (n_records, n_components * n_windows, n_channels=3)\n",
    "    \"\"\"\n",
    "    \n",
    "    X_all_data = []\n",
    "    y_all_data = []\n",
    "    for patient in patient_list:\n",
    "        X, y = get_one_patient_data(data_path, patient, window_len)\n",
    "        \n",
    "        if dawnsample.lower() == \"pca\":\n",
    "            X = reduce_data_pca(X, n_components=n_components)\n",
    "          \n",
    "        elif dawnsample.lower() == \"mean\":\n",
    "            X = reduce_data_mean(X, n_components=n_components)\n",
    "          \n",
    "        elif dawnsample.lower() == \"max\":\n",
    "            X = reduce_data_max(X, n_components=n_components)\n",
    "          \n",
    "        elif dawnsample.lower() == \"mode\":\n",
    "            X = reduce_data_mode(X, n_components=n_components)\n",
    "          \n",
    "        elif dawnsample.lower() == \"simple\":\n",
    "            X = reduce_data_simple(X, n_components=n_components)\n",
    "        \n",
    "        \n",
    "        X_new = np.zeros((X.shape[0] - n_windows, X.shape[1] * (n_windows + 1), X.shape[2]))\n",
    "        \n",
    "        for i in range(0, X.shape[0] - n_windows):\n",
    "            X_buff = X[i]\n",
    "            for j in range(1, n_windows + 1):\n",
    "                X_buff = np.concatenate([X_buff, X[i+j]], axis=0)\n",
    "            X_new[i] = X_buff                            \n",
    "    \n",
    "    \n",
    "        if n_windows != 0:\n",
    "          y = y[(n_windows//2): -(n_windows//2)]\n",
    "      \n",
    "        \n",
    "        X_all_data.append(X_new)\n",
    "        y_all_data.append(y)\n",
    "\n",
    "        #np.save((\"X_p%s.npy\"%(patient)), X_new)\n",
    "        #np.save((\"y_p%s.npy\"%(patient)), y)\n",
    "        \n",
    "    X_all_data = np.concatenate(X_all_data, axis=0)\n",
    "    y_all_data = np.concatenate(y_all_data, axis=0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    return X_all_data, y_all_data\n",
    "  \n",
    "def reduce_data_pca(X, n_components=300):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    X - ndarray of shape (n_samples, n_features)\n",
    "    \n",
    "    Returns:\n",
    "    X, y - reduced data, ndarray of shape (n_records, n_features, n_channels=3)\n",
    "    \"\"\"\n",
    "    pca1 = PCA(n_components)\n",
    "    pca2 = PCA(n_components)\n",
    "    pca3 = PCA(n_components)\n",
    "    \n",
    "    pca1.fit(X[:, :, 0])\n",
    "    pca2.fit(X[:, :, 1])\n",
    "    pca3.fit(X[:, :, 2])\n",
    "    \n",
    "    X1 = pca1.transform(X[:, :, 0])\n",
    "    X2 = pca2.transform(X[:, :, 1])\n",
    "    X3 = pca3.transform(X[:, :, 2])\n",
    "    \n",
    "    X_reduced = np.concatenate([X1, X2, X3], axis=1).reshape(X.shape[0], n_components, 3)\n",
    "    \n",
    "    return X_reduced\n",
    "\n",
    "\n",
    "def reduce_data_max(X, n_components=600):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    X - ndarray of shape (n_samples, n_features)\n",
    "    \n",
    "    Returns:\n",
    "    X, y - reduced data, ndarray of shape (n_records, n_components, n_channels=3)\n",
    "    \"\"\"\n",
    "   \n",
    "    \n",
    "    X_reduced = np.zeros((X.shape[0], n_components, 3))\n",
    "    window_len = X.shape[1] // n_components\n",
    "    \n",
    "    \n",
    "    for i in range(n_components):\n",
    "      \n",
    "      X_reduced[:, i, :] = np.amax(X[:, i * window_len: (i + 1) * window_len, :], axis=1)\n",
    "      \n",
    "    \n",
    "    X_reduced = X_reduced.reshape(X.shape[0], n_components, 3)\n",
    "    \n",
    "    return X_reduced\n",
    "  \n",
    "\n",
    "def reduce_data_mean(X, n_components=600):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    X - ndarray of shape (n_samples, n_features)\n",
    "    \n",
    "    Returns:\n",
    "    X, y - reduced data, ndarray of shape (n_records, n_components, n_channels=3)\n",
    "    \"\"\"\n",
    "   \n",
    "    \n",
    "    X_reduced = np.zeros((X.shape[0], n_components, 3))\n",
    "    window_len = X.shape[1] // n_components\n",
    "    \n",
    "    \n",
    "    for i in range(n_components):\n",
    "      \n",
    "      X_reduced[:, i, :] = np.mean(X[:, i * window_len: (i + 1) * window_len, :], axis=1)\n",
    "         \n",
    "    X_reduced = X_reduced.reshape(X.shape[0], n_components, 3)\n",
    "    \n",
    "    return X_reduced\n",
    "  \n",
    "    \n",
    "def reduce_data_mode(X, n_components=600):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    X - ndarray of shape (n_samples, n_features)\n",
    "    \n",
    "    Returns:\n",
    "    X, y - reduced data, ndarray of shape (n_records, n_components, n_channels=3)\n",
    "    \"\"\"\n",
    "    \n",
    "    from scipy.stats import mode\n",
    "   \n",
    "    X_reduced = np.zeros((X.shape[0], n_components, 3))\n",
    "    window_len = X.shape[1] // n_components\n",
    "       \n",
    "    for i in range(n_components):\n",
    "      \n",
    "      X_reduced[:, i, :] = mode(X[:, i * window_len: (i + 1) * window_len, :], axis=1)\n",
    "         \n",
    "    X_reduced = X_reduced.reshape(X.shape[0], n_components, 3)\n",
    "    \n",
    "    return X_reduced\n",
    "  \n",
    "def reduce_data_simple(X, n_components=600):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    X - ndarray of shape (n_samples, n_features)\n",
    "    \n",
    "    Returns:\n",
    "    X, y - reduced data, ndarray of shape (n_records, n_components, n_channels=3)\n",
    "    \"\"\"\n",
    "   \n",
    "    X_reduced = np.zeros((X.shape[0], n_components, 3))\n",
    "    window_len = X.shape[1] // n_components\n",
    "       \n",
    "    for i in range(n_components):\n",
    "      \n",
    "      X_reduced[:, i, :] = X[:, i * window_len, :]\n",
    "         \n",
    "    X_reduced = X_reduced.reshape(X.shape[0], n_components, 3)\n",
    "    \n",
    "    return X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VT7dhZvRIJrX"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = get_data_for_model(data_path, train_patient_list, window_len=240)\n",
    "X_valid, y_valid = get_data_for_model(data_path, valid_patient_list, window_len=240)\n",
    "X_test, y_test = get_data_for_model(data_path, test_patient_list, window_len=240)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88XbUDyOIJrc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3949, 24000, 3)\n",
      "(890, 24000, 3)\n",
      "(948, 24000, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)\n",
    "np.min(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4oE0-ifHUdJJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train, y_train = get_dawnsampled_data(data_path, train_patient_list, window_len=60, dawnsample=\"pca\", n_components=60, n_windows=12)\n",
    "X_valid, y_valid = get_dawnsampled_data(data_path, valid_patient_list, window_len=60, dawnsample=\"pca\", n_components=60, n_windows=12)\n",
    "X_test, y_test = get_dawnsampled_data(data_path, test_patient_list, window_len=60, dawnsample=\"pca\", n_components=60, n_windows=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "54b8IOL2IJrl"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15463, 780, 3)\n",
      "(15463,)\n",
      "(3481, 780, 3)\n",
      "(3721, 780, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5329\n"
     ]
    }
   ],
   "source": [
    "size = int(np.sqrt(X_train.shape[1]))\n",
    "print(size**2)\n",
    "X_train_new = X_train[:, :size**2, :].reshape(X_train.shape[0], size, size, 3)\n",
    "X_test_new = X_test[:, :size**2, :].reshape(X_test.shape[0], size, size, 3)\n",
    "X_valid_new = X_valid[:, :size**2, :].reshape(X_valid.shape[0], size, size, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15587, 73, 73, 3)\n",
      "(15587,)\n",
      "(3509, 73, 73, 3)\n",
      "(3749, 73, 73, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_new.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid_new.shape)\n",
    "print(X_test_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16, VGG19, Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "whTzvWqWNl7O"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.layers import Conv1D, MaxPooling1D, Activation\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import SGD, adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_net = VGG19(weights='imagenet', \n",
    "                  include_top=False, \n",
    "                  input_shape=(size, size, 3))\n",
    "vgg16_net.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg19 (Model)                (None, 2, 2, 512)         20024384  \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 64)                131136    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 20,155,585\n",
      "Trainable params: 131,201\n",
      "Non-trainable params: 20,024,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(vgg16_net)\n",
    "model.add(Flatten())\n",
    "\n",
    "#model.add(Dense(256))\n",
    "#model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=adam(lr=1e-5), \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [ModelCheckpoint('CNN2_model_raw_data_weights.hdf5', monitor='val_acc', save_best_only=True), EarlyStopping(monitor='val_loss', patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "model.fit(X_train_new, y_train,\n",
    "       batch_size=64, \n",
    "       epochs=30, \n",
    "       validation_data=(X_valid_new, y_valid), \n",
    "       callbacks=callbacks,\n",
    "       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s-ze4t-Sk9BE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_8 (Conv1D)            (None, 778, 64)           640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 778, 64)           256       \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 778, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 776, 64)           12352     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 776, 64)           256       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 388, 64)           0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 388, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_10 (Conv1D)           (None, 386, 128)          24704     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 386, 128)          512       \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 386, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 384, 128)          49280     \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 384, 128)          512       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 192, 128)          0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 192, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_12 (Conv1D)           (None, 190, 256)          98560     \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 190, 256)          1024      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 190, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_13 (Conv1D)           (None, 188, 256)          196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 188, 256)          1024      \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 188, 256)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_14 (Conv1D)           (None, 186, 256)          196864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 186, 256)          1024      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 93, 256)           0         \n",
      "_________________________________________________________________\n",
      "dropout_16 (Dropout)         (None, 93, 256)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 23808)             0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                380944    \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 965,233\n",
      "Trainable params: 962,865\n",
      "Non-trainable params: 2,368\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "NN = Sequential()\n",
    "\n",
    "NN.add(Conv1D( 64, 3, input_shape=(780, 3), activation=\"relu\", kernel_initializer=\"he_uniform\", kernel_regularizer=l2(0.1)))\n",
    "NN.add(BatchNormalization())\n",
    "NN.add(Dropout(0.5))\n",
    "NN.add(Conv1D( 64, 3, activation=\"relu\", kernel_initializer=\"he_uniform\", kernel_regularizer=l2(0.1)))\n",
    "NN.add(BatchNormalization())\n",
    "NN.add(MaxPooling1D(pool_size=2))\n",
    "NN.add(Dropout(0.5))\n",
    "\n",
    "NN.add(Conv1D( 128, 3, activation=\"relu\", kernel_initializer=\"he_uniform\", kernel_regularizer=l2(0.1)))\n",
    "NN.add(BatchNormalization())\n",
    "NN.add(Dropout(0.5))\n",
    "NN.add(Conv1D( 128, 3, activation=\"relu\", kernel_initializer=\"he_uniform\", kernel_regularizer=l2(0.1)))\n",
    "NN.add(BatchNormalization())\n",
    "NN.add(MaxPooling1D(pool_size=2))\n",
    "NN.add(Dropout(0.5))\n",
    "\n",
    "NN.add(Conv1D( 256, 3, activation=\"relu\", kernel_initializer=\"he_uniform\", kernel_regularizer=l2(0.1)))\n",
    "NN.add(BatchNormalization())\n",
    "NN.add(Dropout(0.5))\n",
    "NN.add(Conv1D( 256, 3, activation=\"relu\", kernel_initializer=\"he_uniform\", kernel_regularizer=l2(0.1)))\n",
    "NN.add(BatchNormalization())\n",
    "NN.add(Dropout(0.5))\n",
    "NN.add(Conv1D( 256, 3, activation=\"relu\", kernel_initializer=\"he_uniform\", kernel_regularizer=l2(0.1)))\n",
    "NN.add(BatchNormalization())\n",
    "NN.add(MaxPooling1D( pool_size=2))\n",
    "NN.add(Dropout(0.5))\n",
    "#\n",
    "#NN.add(Conv1D( 512, 3, activation=\"relu\", kernel_initializer=\"he_uniform\", kernel_regularizer=l2(0.01)))\n",
    "#NN.add(BatchNormalization())\n",
    "#NN.add(Dropout(0.5))\n",
    "#NN.add(Conv1D( 512, 3, activation=\"relu\", kernel_initializer=\"he_uniform\", kernel_regularizer=l2(0.01)))\n",
    "#NN.add(BatchNormalization())\n",
    "#NN.add(Dropout(0.5))\n",
    "#NN.add(Conv1D( 512, 3, activation=\"relu\", kernel_initializer=\"he_uniform\", kernel_regularizer=l2(0.01)))\n",
    "#NN.add(BatchNormalization())\n",
    "#NN.add(MaxPooling1D( pool_size=2))\n",
    "#NN.add(Dropout(0.5))\n",
    "NN.add(Flatten())\n",
    "\n",
    "NN.add(Dense(16, activation=\"relu\", kernel_initializer=\"he_uniform\", kernel_regularizer=l2(0.1)))\n",
    "NN.add(BatchNormalization(axis=1))\n",
    "NN.add(Dropout(0.5))\n",
    "\n",
    "NN.add(Dense(16, activation=\"relu\", kernel_initializer=\"he_uniform\", kernel_regularizer=l2(0.1)))\n",
    "NN.add(BatchNormalization(axis=1))\n",
    "NN.add(Dropout(0.5))\n",
    "NN.add(Dense(1, activation=\"sigmoid\", kernel_initializer=\"glorot_uniform\", kernel_regularizer=l2(0.1)))\n",
    "\n",
    "NN.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "print(NN.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4GX6t1xvk80Q"
   },
   "outputs": [],
   "source": [
    "callbacks = [ModelCheckpoint('CNN_model_raw_data_weights.hdf5', monitor='val_acc', save_best_only=True), EarlyStopping(monitor='val_loss', patience=5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pjo6YtmNzqDD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15463 samples, validate on 3481 samples\n",
      "Epoch 1/30\n",
      "13376/15463 [========================>.....] - ETA: 19s - loss: 1.0137 - acc: 0.7273"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "NN.fit(X_train, y_train,\n",
    "       batch_size=64, \n",
    "       shuffle=True,\n",
    "       epochs=30, \n",
    "       validation_data=(X_valid, y_valid), \n",
    "       callbacks=callbacks,\n",
    "       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oyksgYY55H01"
   },
   "outputs": [],
   "source": [
    "scores = NN.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy =\", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g-FGHwxfgtjC"
   },
   "outputs": [],
   "source": [
    "files.download('CNN_model_raw_data_weights.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "518uijixWFc0"
   },
   "outputs": [],
   "source": [
    "# Load best model\n",
    "NN.load_weights(\"CNN_model_raw_data_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8PmvsOTNWLvd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3721/3721 [==============================] - 11s 3ms/step\n",
      "Test accuracy = 0.7127116366568127\n"
     ]
    }
   ],
   "source": [
    "scores = NN.evaluate(X_test, y_test)\n",
    "print(\"Test accuracy =\", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ASQWAR4hWOXq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3481/3481 [==============================] - 12s 4ms/step\n",
      "Valid accuracy = 0.7411663314625643\n"
     ]
    }
   ],
   "source": [
    "scores = NN.evaluate(X_valid, y_valid)\n",
    "print(\"Valid accuracy =\", scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.7275  1w 600s 600c s\n",
    "\n",
    "0.7222  1w 600s 600c b\n",
    "\n",
    "0.7248  1w 600s 300c s\n",
    "\n",
    "0.7152 3w 240s 240c s\n",
    "\n",
    "0.7011 13w 60s 60c s\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = NN.predict(X_train)\n",
    "\n",
    "print(\"\\nTrain set result: \")\n",
    "print(metrics.classification_report(y_train, y_predict))\n",
    "print(\"Confussion matrix: \\n\", metrics.confusion_matrix(y_train, y_predict))\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_train, y_predict)\n",
    "print(\"\\nAccuracy on train set: \", accuracy)\n",
    "\n",
    "y_predict = NN.predict(X_test)\n",
    "\n",
    "print(\"\\nTrain set result: \")\n",
    "print(metrics.classification_report(y_test, y_predict))\n",
    "print(\"Confussion matrix: \\n\", metrics.confusion_matrix(y_test, y_predict))\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_predict)\n",
    "print(\"\\nAccuracy on train set: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZEG-smEOq5Zr"
   },
   "outputs": [],
   "source": [
    "saved_model = NN.to_json()\n",
    "with open(\"CNN_model_raw_data.json\", \"w\") as json_file:\n",
    "    json_file.write(saved_model)\n",
    "    \n",
    "files.download('CNN_model_raw_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kaVfsb3XyaPR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_raw_data.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
