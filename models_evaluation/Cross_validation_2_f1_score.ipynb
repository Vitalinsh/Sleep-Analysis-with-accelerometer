{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"D:\\Study\\Python\\Sleep-Analysis-with-accelerometer\")\n",
    "\n",
    "import prepare_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorce_path = os.path.join(\"D:\\Study\\Python\\Sleep-Analysis-with-accelerometer\", \n",
    "                          \"ICHI14_dataset\\data\")\n",
    "\n",
    "data_path = os.path.join(\"D:\\Study\\Python\\Sleep-Analysis-with-accelerometer\",\n",
    "                         \"statistic_features\", \"stat_features_standardized.csv\")\n",
    "\n",
    "patient_list = ['002','003','005','007','08a','08b','09a','09b', '10a','011','013','014','15a','15b','016',\n",
    "            '017','018','019','020','021','022','023','025','026','027','028','029','030','031','032',\n",
    "            '033','034','035','036','037','038','040','042','043','044','045','047','048','049','051']\n",
    "\n",
    "statistics_list = [\"std_x\", \"std_y\", \"std_z\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the statistic features.\n",
    "#### As scaler=True, firstly we standardize accelerometer data for all dataset, and then calculate statistic features for windows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare_data.save_statistic_features(patient_list, sorce_path=sorce_path, save_path=data_path, \n",
    "#                            window_len=60, n_sleep_stages=1, scaler=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, random_state=5, shuffle=True) # Define the split - into 5 folds #5\n",
    "kf.get_n_splits(patient_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['007', '08a', '09a', '025', '028', '029', '031', '044', '048']\n",
      "['002', '005', '08b', '021', '026', '027', '032', '034', '049']\n",
      "['003', '013', '014', '15b', '020', '022', '035', '036', '045']\n",
      "['09b', '15a', '017', '019', '023', '037', '042', '047', '051']\n",
      "['10a', '011', '016', '018', '030', '033', '038', '040', '043']\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split(patient_list):\n",
    "    #train_patient_list = [patient_list[i] for i in train_index]\n",
    "    test_patient_list = [patient_list[i] for i in test_index]\n",
    "    \n",
    "    print(test_patient_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_others_windows = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic regression\n",
    "### 1.1 Statistic features per window: STD for each of 3 axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_list_std = [\"std_x\", \"std_y\", \"std_z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set result: \n",
      "Accuracy on train set:  0.762588702810105\n",
      "F1-score on train set:  0.7149672846237731\n",
      "\n",
      "Test set result: \n",
      "Accuracy on test set:  0.6735849056603773\n",
      "F1-score on test set:  0.6183121897407611\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      sleep       0.65      0.80      0.71      2178\n",
      "      awake       0.72      0.54      0.62      2062\n",
      "\n",
      "avg / total       0.68      0.67      0.67      4240\n",
      "\n",
      "Confussion matrix: \n",
      " [[1735  443]\n",
      " [ 941 1121]]\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Train set result: \n",
      "Accuracy on train set:  0.742850459091175\n",
      "F1-score on train set:  0.6796357012750456\n",
      "\n",
      "Test set result: \n",
      "Accuracy on test set:  0.7460050462573591\n",
      "F1-score on test set:  0.7449324324324326\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      sleep       0.72      0.78      0.75      2298\n",
      "      awake       0.77      0.72      0.74      2458\n",
      "\n",
      "avg / total       0.75      0.75      0.75      4756\n",
      "\n",
      "Confussion matrix: \n",
      " [[1784  514]\n",
      " [ 694 1764]]\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Train set result: \n",
      "Accuracy on train set:  0.7351894730897385\n",
      "F1-score on train set:  0.705852832319177\n",
      "\n",
      "Test set result: \n",
      "Accuracy on test set:  0.73625843780135\n",
      "F1-score on test set:  0.670680313064419\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      sleep       0.81      0.75      0.78      2589\n",
      "      awake       0.63      0.71      0.67      1559\n",
      "\n",
      "avg / total       0.75      0.74      0.74      4148\n",
      "\n",
      "Confussion matrix: \n",
      " [[1940  649]\n",
      " [ 445 1114]]\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Train set result: \n",
      "Accuracy on train set:  0.7196042548324374\n",
      "F1-score on train set:  0.6898602062116517\n",
      "\n",
      "Test set result: \n",
      "Accuracy on test set:  0.780498970016022\n",
      "F1-score on test set:  0.7288662708510036\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      sleep       0.83      0.81      0.82      2633\n",
      "      awake       0.72      0.74      0.73      1736\n",
      "\n",
      "avg / total       0.78      0.78      0.78      4369\n",
      "\n",
      "Confussion matrix: \n",
      " [[2121  512]\n",
      " [ 447 1289]]\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Train set result: \n",
      "Accuracy on train set:  0.7374521783817736\n",
      "F1-score on train set:  0.7056714889258737\n",
      "\n",
      "Test set result: \n",
      "Accuracy on test set:  0.7118839244587748\n",
      "F1-score on test set:  0.6597769921131358\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      sleep       0.79      0.71      0.75      2636\n",
      "      awake       0.62      0.71      0.66      1706\n",
      "\n",
      "avg / total       0.72      0.71      0.71      4342\n",
      "\n",
      "Confussion matrix: \n",
      " [[1878  758]\n",
      " [ 493 1213]]\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Mean accuracy = 0.7296462568387766\n",
      "\n",
      "Mean f1-score = 0.6845136396403504\n",
      "Wall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracy_list = []\n",
    "f1_score_list = []\n",
    "for train_index, test_index in kf.split(patient_list):\n",
    "    train_patient_list = [patient_list[i] for i in train_index]\n",
    "    test_patient_list = [patient_list[i] for i in test_index]\n",
    "    \n",
    "    X_train, y_train = prepare_data.load_stat_features_others_windows(train_patient_list,\n",
    "                                                                      data_path=data_path,\n",
    "                                                                      n_others_windows=n_others_windows,\n",
    "                                                                      statistics_list=statistics_list_std)\n",
    "    X_test, y_test = prepare_data.load_stat_features_others_windows(test_patient_list,\n",
    "                                                                    data_path=data_path, \n",
    "                                                                    n_others_windows=n_others_windows,\n",
    "                                                                    statistics_list=statistics_list_std)\n",
    "    \n",
    "    \n",
    "    weights = np.ones(y_train.shape)\n",
    "    weights[y_train==1] = 1.8\n",
    "\n",
    "    model1 = LogisticRegression()\n",
    "    model1.fit(X_train, y_train, sample_weight=weights)\n",
    "    \n",
    "    print(\"\\nTrain set result: \")\n",
    "    y_predict = model1.predict(X_train)\n",
    "    accuracy_train = metrics.accuracy_score(y_train, y_predict)\n",
    "    f1_train = metrics.f1_score(y_train, y_predict)\n",
    "    print(\"Accuracy on train set: \", accuracy_train)\n",
    "    print(\"F1-score on train set: \", f1_train)\n",
    "    \n",
    "    print(\"\\nTest set result: \")\n",
    "    y_predict = model1.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_predict)\n",
    "    f1_test = metrics.f1_score(y_test, y_predict)\n",
    "    accuracy_list.append(accuracy)\n",
    "    f1_score_list.append(f1_test)\n",
    "    print(\"Accuracy on test set: \", accuracy)\n",
    "    print(\"F1-score on test set: \", f1_test)\n",
    "    \n",
    "    print(metrics.classification_report(y_test, y_predict, target_names=[\"sleep\", \"awake\"]))\n",
    "    print(\"Confussion matrix: \\n\", metrics.confusion_matrix(y_test, y_predict))\n",
    "    print(\"\\n-------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nMean accuracy =\", np.mean(accuracy_list))    \n",
    "print(\"\\nMean f1-score =\", np.mean(f1_score_list))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Results:\n",
    "\n",
    "weight for awake class = 1:\n",
    "    \n",
    "    30 windows: acc =  0.7487, f1-score = 0.6532\n",
    "    \n",
    "The problem is that we detect more sleep class than awake. So, the algorithm little overestimates the sleep. One of the reasons may be that we have little more windows for sleep class.\n",
    "\n",
    "weight for awake class = 1.5:\n",
    "    \n",
    "    30 windows: acc = 0.7415, f1-score = 0.6794\n",
    "    \n",
    "weight for awake class = 1.7:\n",
    "    \n",
    "    30 windows: acc = 0.7342, f1-score = 0.6836\n",
    "\n",
    "weight for awake class = 1.8:\n",
    "    \n",
    "    30 windows: acc = 0.7296, f1-score = 0.6845\n",
    "    \n",
    "    32 windows: acc = 0.7307, f1-score = 0.6840\n",
    "    \n",
    "weight for awake class = 1.9:\n",
    "    \n",
    "    30 windows: acc = 0.7221, f1-score = 0.6826\n",
    "\n",
    "weight for awake class = 2:\n",
    "    \n",
    "    30 windows: acc = 0.7147, f1-score = 0.6810\n",
    "    \n",
    "To conclude, it seems reasonable to use weight for awake class = 1.8, as we have best f1-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1.2 Results for only axis X:\n",
    "\n",
    "weight for awake class = 1:\n",
    "    \n",
    "    32 windows: acc =  0.7263, f1-score = 0.6219\n",
    "    \n",
    "weight for awake class = 1.5:\n",
    "    \n",
    "    32 windows: acc = 0.7150, f1-score = 0.6514\n",
    "    \n",
    "weight for awake class = 1.7:\n",
    "    \n",
    "    32 windows: acc = 0.7082, f1-score = 0.6602\n",
    "\n",
    "weight for awake class = 1.8:\n",
    "    \n",
    "    30 windows: acc = 0.7038, f1-score = 0.6651\n",
    "    \n",
    "    32 windows: acc = 0.7047, f1-score = 0.6642\n",
    "    \n",
    "weight for awake class = 1.9:\n",
    "    \n",
    "    32 windows: acc = 0.6976, f1-score = 0.6648"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Statistic features per window: PTP for each of 3 axis (peak to peak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_list_ptp = [\"ptp_x\", \"ptp_y\", \"ptp_z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set result: \n",
      "Accuracy on train set:  0.763894408174851\n",
      "F1-score on train set:  0.7163222154014051\n",
      "\n",
      "Test set result: \n",
      "Accuracy on test set:  0.6712264150943397\n",
      "F1-score on test set:  0.6129927817878956\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      sleep       0.65      0.80      0.71      2178\n",
      "      awake       0.72      0.54      0.61      2062\n",
      "\n",
      "avg / total       0.68      0.67      0.66      4240\n",
      "\n",
      "Confussion matrix: \n",
      " [[1742  436]\n",
      " [ 958 1104]]\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Train set result: \n",
      "Accuracy on train set:  0.7502193110708228\n",
      "F1-score on train set:  0.6879976623566366\n",
      "\n",
      "Test set result: \n",
      "Accuracy on test set:  0.7106812447434819\n",
      "F1-score on test set:  0.7129745515227368\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      sleep       0.69      0.73      0.71      2298\n",
      "      awake       0.73      0.70      0.71      2458\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4756\n",
      "\n",
      "Confussion matrix: \n",
      " [[1671  627]\n",
      " [ 749 1709]]\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Train set result: \n",
      "Accuracy on train set:  0.7320833568645169\n",
      "F1-score on train set:  0.7020849032906304\n",
      "\n",
      "Test set result: \n",
      "Accuracy on test set:  0.7468659594985535\n",
      "F1-score on test set:  0.6820109024833435\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      sleep       0.82      0.76      0.79      2589\n",
      "      awake       0.65      0.72      0.68      1559\n",
      "\n",
      "avg / total       0.75      0.75      0.75      4148\n",
      "\n",
      "Confussion matrix: \n",
      " [[1972  617]\n",
      " [ 433 1126]]\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Train set result: \n",
      "Accuracy on train set:  0.7271531510923024\n",
      "F1-score on train set:  0.6935970714790316\n",
      "\n",
      "Test set result: \n",
      "Accuracy on test set:  0.7924010070954451\n",
      "F1-score on test set:  0.7359534206695778\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      sleep       0.82      0.83      0.83      2633\n",
      "      awake       0.74      0.73      0.74      1736\n",
      "\n",
      "avg / total       0.79      0.79      0.79      4369\n",
      "\n",
      "Confussion matrix: \n",
      " [[2198  435]\n",
      " [ 472 1264]]\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Train set result: \n",
      "Accuracy on train set:  0.7411066065208702\n",
      "F1-score on train set:  0.7089858793324775\n",
      "\n",
      "Test set result: \n",
      "Accuracy on test set:  0.7215568862275449\n",
      "F1-score on test set:  0.6708412741628098\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      sleep       0.80      0.72      0.76      2636\n",
      "      awake       0.63      0.72      0.67      1706\n",
      "\n",
      "avg / total       0.73      0.72      0.72      4342\n",
      "\n",
      "Confussion matrix: \n",
      " [[1901  735]\n",
      " [ 474 1232]]\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Mean accuracy = 0.728546302531873\n",
      "\n",
      "Mean f1-score = 0.6829545861252727\n",
      "Wall time: 10.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracy_list = []\n",
    "f1_score_list = []\n",
    "for train_index, test_index in kf.split(patient_list):\n",
    "    train_patient_list = [patient_list[i] for i in train_index]\n",
    "    test_patient_list = [patient_list[i] for i in test_index]\n",
    "    \n",
    "    X_train, y_train = prepare_data.load_stat_features_others_windows(train_patient_list,\n",
    "                                                                      data_path=data_path,\n",
    "                                                                      n_others_windows=n_others_windows,\n",
    "                                                                      statistics_list=statistics_list_ptp)\n",
    "    X_test, y_test = prepare_data.load_stat_features_others_windows(test_patient_list,\n",
    "                                                                    data_path=data_path, \n",
    "                                                                    n_others_windows=n_others_windows,\n",
    "                                                                    statistics_list=statistics_list_ptp)\n",
    "    \n",
    "    \n",
    "    weights = np.ones(y_train.shape)\n",
    "    weights[y_train==1] = 1.8\n",
    "\n",
    "    model1 = LogisticRegression()\n",
    "    model1.fit(X_train, y_train, sample_weight=weights)\n",
    "    \n",
    "    print(\"\\nTrain set result: \")\n",
    "    y_predict = model1.predict(X_train)\n",
    "    accuracy_train = metrics.accuracy_score(y_train, y_predict)\n",
    "    f1_train = metrics.f1_score(y_train, y_predict)\n",
    "    print(\"Accuracy on train set: \", accuracy_train)\n",
    "    print(\"F1-score on train set: \", f1_train)\n",
    "    \n",
    "    print(\"\\nTest set result: \")\n",
    "    y_predict = model1.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_predict)\n",
    "    f1_test = metrics.f1_score(y_test, y_predict)\n",
    "    accuracy_list.append(accuracy)\n",
    "    f1_score_list.append(f1_test)\n",
    "    print(\"Accuracy on test set: \", accuracy)\n",
    "    print(\"F1-score on test set: \", f1_test)\n",
    "    \n",
    "    print(metrics.classification_report(y_test, y_predict, target_names=[\"sleep\", \"awake\"]))\n",
    "    print(\"Confussion matrix: \\n\", metrics.confusion_matrix(y_test, y_predict))\n",
    "    print(\"\\n-------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nMean accuracy =\", np.mean(accuracy_list))    \n",
    "print(\"\\nMean f1-score =\", np.mean(f1_score_list))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Results:\n",
    "\n",
    "weight for awake class = 1:\n",
    "    \n",
    "    30 windows: acc = 0.7442, f1-score = 0.6516\n",
    "\n",
    "weight for awake class = 1.5:\n",
    "    \n",
    "    30 windows: acc = 0.7376, f1-score = 0.6767\n",
    "    \n",
    "weight for awake class = 1.7:\n",
    "    \n",
    "    30 windows: acc = 0.7317, f1-score = 0.6814\n",
    "\n",
    "weight for awake class = 1.8:\n",
    "    \n",
    "    30 windows: acc = 0.7285, f1-score = 0.6830\n",
    "\n",
    "weight for awake class = 1.9:\n",
    "    \n",
    "    30 windows: acc = 0.7234, f1-score = 0.6833\n",
    "\n",
    "weight for awake class = 2:\n",
    "    \n",
    "    30 windows: acc = 0.7178, f1-score = 0.6831\n",
    "    \n",
    "To conclude, it seems reasonable to use weight for awake class = 1.8, as we have good f1-score and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Gradient Boosting Classifier\n",
    "### 2.1 Statistic features per window: STD for each of 3 axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics_list_std = [\"std_x\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train set result: \n",
      "Accuracy on train set:  0.795004257734885\n",
      "F1-score on train set:  0.7451838261237739\n",
      "\n",
      "Test set result: \n",
      "Accuracy on test set:  0.6695754716981132\n",
      "F1-score on test set:  0.6193969030154849\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      sleep       0.65      0.78      0.71      2178\n",
      "      awake       0.70      0.55      0.62      2062\n",
      "\n",
      "avg / total       0.68      0.67      0.66      4240\n",
      "\n",
      "Confussion matrix: \n",
      " [[1699  479]\n",
      " [ 922 1140]]\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Train set result: \n",
      "Accuracy on train set:  0.7815076905082169\n",
      "F1-score on train set:  0.7161525604011547\n",
      "\n",
      "Test set result: \n",
      "Accuracy on test set:  0.70878889823381\n",
      "F1-score on test set:  0.6976642654442262\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      sleep       0.67      0.77      0.72      2298\n",
      "      awake       0.75      0.65      0.70      2458\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4756\n",
      "\n",
      "Confussion matrix: \n",
      " [[1773  525]\n",
      " [ 860 1598]]\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Train set result: \n",
      "Accuracy on train set:  0.7751171852939516\n",
      "F1-score on train set:  0.7337167313093487\n",
      "\n",
      "Test set result: \n",
      "Accuracy on test set:  0.7442140790742526\n",
      "F1-score on test set:  0.6574103971585404\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      sleep       0.79      0.80      0.80      2589\n",
      "      awake       0.66      0.65      0.66      1559\n",
      "\n",
      "avg / total       0.74      0.74      0.74      4148\n",
      "\n",
      "Confussion matrix: \n",
      " [[2069  520]\n",
      " [ 541 1018]]\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Train set result: \n",
      "Accuracy on train set:  0.763753860231042\n",
      "F1-score on train set:  0.7233273056057865\n",
      "\n",
      "Test set result: \n",
      "Accuracy on test set:  0.7839322499427787\n",
      "F1-score on test set:  0.7282671272308578\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      sleep       0.82      0.82      0.82      2633\n",
      "      awake       0.73      0.73      0.73      1736\n",
      "\n",
      "avg / total       0.78      0.78      0.78      4369\n",
      "\n",
      "Confussion matrix: \n",
      " [[2160  473]\n",
      " [ 471 1265]]\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Train set result: \n",
      "Accuracy on train set:  0.7734825558156798\n",
      "F1-score on train set:  0.7370235333112364\n",
      "\n",
      "Test set result: \n",
      "Accuracy on test set:  0.7213265776140028\n",
      "F1-score on test set:  0.6532951289398281\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      sleep       0.78      0.76      0.77      2636\n",
      "      awake       0.64      0.67      0.65      1706\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4342\n",
      "\n",
      "Confussion matrix: \n",
      " [[1992  644]\n",
      " [ 566 1140]]\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "Mean accuracy = 0.7255674553125915\n",
      "\n",
      "Mean f1-score = 0.6712067643577876\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracy_list = []\n",
    "f1_score_list = []\n",
    "for train_index, test_index in kf.split(patient_list):\n",
    "    train_patient_list = [patient_list[i] for i in train_index]\n",
    "    test_patient_list = [patient_list[i] for i in test_index]\n",
    "    \n",
    "    X_train, y_train = prepare_data.load_stat_features_others_windows(train_patient_list,\n",
    "                                                                      data_path=data_path,\n",
    "                                                                      n_others_windows=n_others_windows)\n",
    "    X_test, y_test = prepare_data.load_stat_features_others_windows(test_patient_list,\n",
    "                                                                    data_path=data_path, \n",
    "                                                                    n_others_windows=n_others_windows)\n",
    "    \n",
    "    \n",
    "    weights = np.ones(y_train.shape)\n",
    "    weights[y_train==1] = 1.5\n",
    "\n",
    "    model1 = GradientBoostingClassifier(n_estimators=40, max_depth=4)\n",
    "    model1.fit(X_train, y_train, sample_weight=weights)\n",
    "    \n",
    "    print(\"\\nTrain set result: \")\n",
    "    y_predict = model1.predict(X_train)\n",
    "    accuracy_train = metrics.accuracy_score(y_train, y_predict)\n",
    "    f1_train = metrics.f1_score(y_train, y_predict)\n",
    "    print(\"Accuracy on train set: \", accuracy_train)\n",
    "    print(\"F1-score on train set: \", f1_train)\n",
    "    \n",
    "    print(\"\\nTest set result: \")\n",
    "    y_predict = model1.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, y_predict)\n",
    "    f1_test = metrics.f1_score(y_test, y_predict)\n",
    "    accuracy_list.append(accuracy)\n",
    "    f1_score_list.append(f1_test)\n",
    "    print(\"Accuracy on test set: \", accuracy)\n",
    "    print(\"F1-score on test set: \", f1_test)\n",
    "    \n",
    "    print(metrics.classification_report(y_test, y_predict, target_names=[\"sleep\", \"awake\"]))\n",
    "    print(\"Confussion matrix: \\n\", metrics.confusion_matrix(y_test, y_predict))\n",
    "    print(\"\\n-------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nMean accuracy =\", np.mean(accuracy_list))    \n",
    "print(\"\\nMean f1-score =\", np.mean(f1_score_list))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Results:\n",
    "##### Parameters: n_estimators = 40, max_depth = 4\n",
    "\n",
    "weight for awake class = 1:\n",
    "    \n",
    "    30 windows: acc = 0.7399, f1-score = 0.6500\n",
    "    \n",
    "weight for awake class = 1.2:\n",
    "    \n",
    "    30 windows: acc = 0.7368, f1-score = 0.6616\n",
    "    \n",
    "weight for awake class = 1.3:\n",
    "    \n",
    "    30 windows: acc = 0.7332, f1-score = 0.6652\n",
    "\n",
    "weight for awake class = 1.5:\n",
    "    \n",
    "    30 windows: acc = 0.7255, f1-score = 0.6711\n",
    "    \n",
    "weight for awake class = 1.7:\n",
    "    \n",
    "    30 windows: acc = 0.7115, f1-score = 0.6685\n",
    "\n",
    "weight for awake class = 1.8:\n",
    "    \n",
    "    30 windows: acc = 0.7092, f1-score = 0.6731  - best\n",
    "\n",
    "weight for awake class = 1.9:\n",
    "    \n",
    "    30 windows: acc = 0.7022, f1-score = 0.6727\n",
    "     \n",
    "##### Parameters: n_estimators = 20, max_depth = 4\n",
    "\n",
    "weight for awake class = 1.2:\n",
    "    \n",
    "    30 windows: acc = 0.7338, f1-score = 0.6530\n",
    "\n",
    "weight for awake class = 1.5:\n",
    "    \n",
    "    30 windows: acc = 0.7206, f1-score = 0.6648\n",
    "    \n",
    "weight for awake class = 1.7:\n",
    "    \n",
    "    30 windows: acc = 0.7065, f1-score = 0.6681\n",
    "\n",
    "weight for awake class = 1.8:\n",
    "    \n",
    "    30 windows: acc = 0.7019, f1-score = 0.6724"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
